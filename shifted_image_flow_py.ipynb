{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmpRoaOT0oV+e5rzrZKHNY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adyasha95/feature-tracking-opencv-demos/blob/main/shifted_image_flow_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhC9RYWemn47"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Lucas–Kanade optical flow on a real image sequence created by synthetic shifts.\n",
        "\n",
        "By default, downloads OpenCV's sample 'building.jpg' and generates a sequence\n",
        "by shifting it (dx=+2 px, dy=+1 px per frame), then tracks Shi–Tomasi features.\n",
        "\n",
        "Usage:\n",
        "  python shifted_image_flow.py\n",
        "  python shifted_image_flow.py --image path/to/your.jpg\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "DEFAULT_URL = \"https://raw.githubusercontent.com/opencv/opencv/master/samples/data/building.jpg\"\n",
        "\n",
        "def load_gray_from_path_or_url(path: str | None):\n",
        "    if path:\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        assert img is not None, f\"Failed to read image at: {path}\"\n",
        "        return img\n",
        "    # Download from URL\n",
        "    resp = urllib.request.urlopen(DEFAULT_URL).read()\n",
        "    img_arr = np.asarray(bytearray(resp), dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_arr, cv2.IMREAD_GRAYSCALE)\n",
        "    assert img is not None, \"Failed to download/decode default image.\"\n",
        "    return img\n",
        "\n",
        "def shift_image(img: np.ndarray, dx: int, dy: int) -> np.ndarray:\n",
        "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
        "    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--image\", type=str, default=None, help=\"Path to a local image (optional)\")\n",
        "    parser.add_argument(\"--frames\", type=int, default=20)\n",
        "    parser.add_argument(\"--dx\", type=int, default=2)\n",
        "    parser.add_argument(\"--dy\", type=int, default=1)\n",
        "    parser.add_argument(\"--max_corners\", type=int, default=250)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    base = load_gray_from_path_or_url(args.image)\n",
        "    frames = [shift_image(base, i * args.dx, i * args.dy) for i in range(args.frames)]\n",
        "\n",
        "    # Detect corners on first frame\n",
        "    p0 = cv2.goodFeaturesToTrack(frames[0], maxCorners=args.max_corners, qualityLevel=0.01, minDistance=8, blockSize=7)\n",
        "    if p0 is None:\n",
        "        raise SystemExit(\"No corners found. Try a more textured image or adjust parameters.\")\n",
        "    p0 = np.float32(p0)\n",
        "\n",
        "    lk_params = dict(\n",
        "        winSize=(21, 21),\n",
        "        maxLevel=3,\n",
        "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01),\n",
        "    )\n",
        "\n",
        "    mask = np.zeros((frames[0].shape[0], frames[0].shape[1], 3), dtype=np.uint8)\n",
        "    prev = frames[0]\n",
        "    out_img = None\n",
        "\n",
        "    for i in range(1, len(frames)):\n",
        "        curr = frames[i]\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(prev, curr, p0, None, **lk_params)\n",
        "        if p1 is None:\n",
        "            break\n",
        "\n",
        "        good_new = p1[st == 1]\n",
        "        good_old = p0[st == 1]\n",
        "\n",
        "        frame_bgr = cv2.cvtColor(curr, cv2.COLOR_GRAY2BGR)\n",
        "        for (x1, y1), (x0, y0) in zip(good_new, good_old):\n",
        "            x1, y1, x0, y0 = int(x1), int(y1), int(x0), int(y0)\n",
        "            mask = cv2.line(mask, (x1, y1), (x0, y0), (0, 255, 0), 1)\n",
        "            frame_bgr = cv2.circle(frame_bgr, (x1, y1), 2, (0, 0, 255), -1)\n",
        "\n",
        "        out_img = cv2.add(frame_bgr, mask)\n",
        "        prev = curr.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    if out_img is not None:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(out_img[..., ::-1])  # BGR->RGB\n",
        "        plt.title(\"Optical Flow Tracks (Shifted Real Image)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}